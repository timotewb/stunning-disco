{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nest_asyncio\n",
    "\n",
    "# nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# llm = Ollama(model=\"llama3\", request_timeout=120.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding mdoel\n",
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core import Settings\n",
    "\n",
    "# Settings.llm = llm\n",
    "# Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking\n",
    "Credit: [link](https://github.com/xbeat/Machine-Learning/blob/main/Optimizing%20RAG%20with%20Document%20Chunking%20Techniques%20Using%20Python.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Document Chunking (characters)\n",
    "\n",
    "Document chunking is a crucial technique in Retrieval-Augmented Generation (RAG) systems that involves breaking down large documents into smaller, manageable pieces. This process improves retrieval efficiency and relevance in RAG applications. We'll explore various chunking methods, starting with fixed-size chunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a ', 'sample doc', 'ument for ', 'chunking d', 'emonstrati', 'on.']\n"
     ]
    }
   ],
   "source": [
    "def chunk_document(document, chunk_size):\n",
    "    return [document[i:i+chunk_size] for i in range(0, len(document), chunk_size)]\n",
    "\n",
    "text = \"This is a sample document for chunking demonstration.\"\n",
    "chunks = chunk_document(text, 10)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Fixed-Size Chunking\n",
    "\n",
    "Fixed-size chunking divides a document into segments of equal length, regardless of content boundaries. This method is simple to implement but may split sentences or paragraphs awkwardly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/timotewb/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/timotewb/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a sample document.', 'It contains multiple sentences.', 'We will chunk it using fixed-size method.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def fixed_size_chunking(text: str, chunk_size: int) -> list[str]:\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) <= chunk_size:\n",
    "            current_chunk += sentence + \" \"\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence + \" \"\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "text = \"This is a sample document. It contains multiple sentences. We will chunk it using fixed-size method.\"\n",
    "chunks: list[str] = fixed_size_chunking(text, 50)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Recursive Chunking\n",
    "\n",
    "Recursive chunking involves dividing a document into increasingly smaller segments based on a set of rules or conditions. This method can better preserve the document's structure and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a longer document f', 'or recursive chunking demons', 'tration. It contains multip', 'le sentences and paragraphs.']\n"
     ]
    }
   ],
   "source": [
    "def recursive_chunking(text, max_chunk_size, min_chunk_size):\n",
    "    if len(text) <= max_chunk_size:\n",
    "        return [text]\n",
    "    \n",
    "    mid = len(text) // 2\n",
    "    left_chunk = text[:mid]\n",
    "    right_chunk = text[mid:]\n",
    "    \n",
    "    if len(left_chunk) < min_chunk_size or len(right_chunk) < min_chunk_size:\n",
    "        return [text]\n",
    "    \n",
    "    return recursive_chunking(left_chunk, max_chunk_size, min_chunk_size) + \\\n",
    "           recursive_chunking(right_chunk, max_chunk_size, min_chunk_size)\n",
    "\n",
    "text = \"This is a longer document for recursive chunking demonstration. It contains multiple sentences and paragraphs.\"\n",
    "chunks = recursive_chunking(text, 50, 20)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
